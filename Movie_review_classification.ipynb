{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, serveral classification model will be used on a dataset of 50,000 movie comments. All the comments are labeld either \"positive\" or \"negative\".\n",
    "\n",
    "I. Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "11557297\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "print(data.head())\n",
    "print(data[\"review\"].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have total 11,557,297 words in this dataset. However, there are still tags and other special symbols in the review, therefore, we have clean up these texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x141e4839f48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_labels = [\"positive\", \"negative\"]\n",
    "plt.figure(figsize = (10,6))\n",
    "data[\"sentiment\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 2 labels are well balanced\n",
    "\n",
    "II. Text pre-proccessing and splitting data\n",
    "\n",
    "Let's take a closer look at couple of review to see what kinds of cleaning techniques we should consider to use for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, we will use steps: remove stop words, change text to lower case, remove punctuation, remove bad characters, special characters, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define regular expression into a pattern for later text cleansing\n",
    "re1 = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "re2 = re.compile('[^0-9a-z #+_]')\n",
    "re3 = set(stopwords.words('english'))\n",
    "#define a function that take a string as parameter and return the cleaned text as the result\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re1.sub(\" \", text)\n",
    "    text = re2.sub(\" \", text)\n",
    "    text = \" \".join(word for word in text.split() if word not in re3)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at previous data we looked at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching 1 oz episode hooked right exactly happened br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away br br would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thought wonderful way spend time hot summer weekend sitting air conditioned theater watching light hearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown love br br laughed one woody comedies years dare say decade never impressed scarlet johanson managed tone sexy image jumped right average spirited young woman br br may crown jewel career wittier devil wears prada interesting superman great comedy go see friends'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looked better and cleaner now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6183125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 6,183,125 words left after removing stop words, and cleaning text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"review\"]\n",
    "y = data[\"sentiment\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Implement models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the dataset, we will convert our text review to a matrix of token counts (CounterVectorizer), then transform a count matrix to a normalized tf-idf representation(TfidfTransformer). Final step is train our classifier. Because the processes using CounterVectorizer and TfidfTransformer is the same for every model, we will apply Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Naive Bayes Classifier for Multinomial Models\n",
    "We will start with Naive Bayes, which provides a baseline for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.87      0.88      0.87      5044\n",
      "    negative       0.88      0.86      0.87      4956\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n",
      "Naive Bayes Model's accuracy: 0.8709\n"
     ]
    }
   ],
   "source": [
    "nbmodel = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])\n",
    "nbmodel.fit(x_train, y_train)\n",
    "\n",
    "y_pred = nbmodel.predict(x_test)\n",
    "\n",
    "accuracyNB = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=my_labels))\n",
    "print(f\"Naive Bayes Model's accuracy: {accuracyNB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved 87% accuracy\n",
    "\n",
    "    2. Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.91      0.78      0.84      5044\n",
      "    negative       0.80      0.92      0.86      4956\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "Linear Support Vector Machine's accuracy: 0.8504\n"
     ]
    }
   ],
   "source": [
    "sgdmodel = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),])\n",
    "sgdmodel.fit(x_train, y_train)\n",
    "\n",
    "y_pred = sgdmodel.predict(x_test)\n",
    "\n",
    "accuracy_sgd = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=my_labels))\n",
    "print(f\"Linear Support Vector Machine's accuracy: {accuracy_sgd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved 85% accuracy, 2% lower than Naive Bayes.\n",
    "    3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.90      0.89      0.89      5044\n",
      "    negative       0.88      0.90      0.89      4956\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "Logistic Regression's accuracy: 0.8924\n"
     ]
    }
   ],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), \n",
    "                   ('clf', LogisticRegression(n_jobs=1, C=100, max_iter = 500)),])\n",
    "logreg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "accuracy_log = accuracy_score(y_pred, y_test)\n",
    "print(classification_report(y_test, y_pred,target_names=my_labels))\n",
    "print(f\"Logistic Regression's accuracy: {accuracy_log}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 89% which is higher than both Naive Bayes and SVM.\n",
    "With above simple linear model, we have achieved a high accuracy of 89%. In the next part, we will use the same dataset to fit in other advanced techniques such as word embedding (Word2Vec and Doc2vec) and neutral networks with keras.\n",
    "    4. Word2vec and Logistic Regression\n",
    "\n",
    "The principals behind Word2vec is using the surrounding words to represent the target words with a Neural Network whose hidden layer encodes the word representation.\n",
    "\n",
    "First we will load word2vec model. It has been pre-trained by Google on a 100 billion word Google News corpus. You can download it from here: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", \n",
    "                                                     binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use average of two word vectors for BOW approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "#Warning for exceptional cases. If there is, those will be remove from the dataset.\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will tokenize the text then, apply to the \"review\" column and finally, apply word vector averaging to tokenized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "    \n",
    "train, test = train_test_split(data, test_size=0.3, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda data: w2v_tokenize_text(data['review']), axis=1).values\n",
    "train_tokenized = train.apply(lambda data: w2v_tokenize_text(data['review']), axis=1).values\n",
    "\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit the train data to our logistic model and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.85      0.85      0.85      7411\n",
      "    negative       0.86      0.86      0.86      7589\n",
      "\n",
      "    accuracy                           0.86     15000\n",
      "   macro avg       0.86      0.86      0.86     15000\n",
      "weighted avg       0.86      0.86      0.86     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5, max_iter = 300)\n",
    "logreg = logreg.fit(X_train_word_average, train['sentiment'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('accuracy %s' % accuracy_score(y_pred, test['sentiment']))\n",
    "print(classification_report(test['sentiment'], y_pred,target_names=my_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It achives 85.62% accuracy. It is not really an impressing result. In fact, it is only a little higher than our linear classification. Let's try the Doc2vec.\n",
    "    5. Doc2vec and Logistic Regression\n",
    "The same idea of Word2vec is extended as instead of using surrounding words, now, we will consider using sentences or documents. There are times words can not capture so much meanings, we need relationship between sentences or documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n",
    "x_train = label_sentences(x_train, 'Train')\n",
    "x_test = label_sentences(x_test, 'Test')\n",
    "all_data = x_train + x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of tagged document in our \"all_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['pre', 'release', 'version', '1933', 'baby', 'face', 'would', 'make', 'ideal', 'introduction', 'corporate', 'seminar', 'sexual', 'harassment', 'mentored', 'nietszchean', 'professor', 'lily', 'powers', 'rises', 'life', 'easy', 'virtue', 'father', 'speakeasy', 'rapid', 'climb', 'corporate', 'ladder', 'large', 'bank', 'rung', 'ladder', 'executive', 'brain', 'belt', 'ethics', 'locked', 'vault', 'film', 'victims', 'except', 'lily', 'childhood', 'destroyed', 'abusive', 'exploitative', 'father', 'destructive', 'relationship', 'father', 'suggests', 'lily', 'hidden', 'motive', 'using', 'men', 'advance', 'without', 'regard', 'fate', 'lily', 'cynical', 'obvious', 'approach', 'men', 'targets', 'willingly', 'betray', 'wives', 'fianc', 'trade', 'jobs', 'sexual', 'favors', 'perhaps', 'bank', 'failures', '1930', 'owed', 'less', 'economics', 'morally', 'corrupt', 'executives', 'distracted', 'ambitious', 'women', 'br', 'br', 'plot', 'moves', 'fast', 'camera', 'amusingly', 'moves', 'window', 'window', 'fa', 'ade', 'office', 'building', 'lily', 'climbs', 'ever', 'higher', 'barbara', 'stanwyck', 'reveled', 'tough', 'hard', 'bitten', 'roles', 'top', 'form', 'sentiment', 'intrude', 'ready', 'climb', 'next', 'rung', 'african', 'american', 'confidante', 'chico', 'receives', 'lily', 'affection', 'trust', 'loyalty', 'enlightened', 'times', 'fresh', 'natural', 'beauty', 'theresa', 'harris', 'plays', 'chico', 'would', 'men', 'throwing', 'furs', 'penthouses', 'stanwyck', 'often', 'appears', 'overly', 'made', 'stiffly', 'coiffed', 'comparison', 'harris', 'however', 'despite', 'stanwyck', 'tough', 'demeanor', 'obvious', 'tactics', 'artificial', 'visage', 'manages', 'leave', 'trail', 'duped', 'seduced', 'men', 'including', 'douglass', 'dumbrille', 'donald', 'cook', 'young', 'john', 'wayne', 'br', 'br', 'preferred', 'version', 'baby', 'face', '76', 'minute', 'restored', 'cut', 'edited', 'release', 'version', 'film', 'shyly', 'turns', 'hard', 'facts', 'longer', 'cut', 'restores', 'makes', 'explicit', 'perhaps', 'darryl', 'zanuck', 'wrote', 'story', 'assumed', 'name', 'intended', 'lesson', 'quoting', 'nietszche', 'whose', 'views', 'women', 'controversial', 'however', 'despite', 'alphonse', 'ethier', 'lectures', 'advice', 'defeated', 'life', 'lily', 'grab', 'power', 'money', 'likely', 'owed', 'upbringing', 'father', 'professorial', 'mentor', 'however', 'philosophy', 'distraction', 'short', 'fast', 'paced', 'entertaining', 'baby', 'face', 'contemporary', 'morality', 'wall', 'street', 'substitute', 'gordon', 'gecko', 'nietszche', 'lily', 'could', 'declared', 'guiding', 'philosophy', 'greed', 'good'], tags=['Train_0']),\n",
       " TaggedDocument(words=['shining', 'wit', 'visual', 'flair', 'iconic', 'performance', 'jack', 'nicholson', 'ausentes', 'however', 'none', 'things', 'although', 'borrow', 'classic', 'forebear', 'wit', 'man', 'hacking', 'door', 'woman', 'running', 'around', 'shrieking', 'clutching', 'huge', 'kitchen', 'knife', 'unlike', 'stanley', 'kubrick', 'great', 'psychological', 'horror', 'film', 'ausentes', 'work', 'resonates', 'singular', 'lack', 'genius', 'magnificently', 'comically', 'awful', 'makes', 'spice', 'girls', 'movie', 'look', 'like', 'work', 'vital', 'art', 'ausentes', 'tale', 'family', 'moves', 'gated', 'community', 'suburbs', 'well', 'world', 'live', 'peace', 'tranquillity', 'calmly', 'go', 'business', 'away', 'mean', 'old', 'city', 'streets', 'ariadna', 'gill', 'character', 'julia', 'starts', 'getting', 'spooked', 'things', 'insist', 'going', 'bump', 'night', 'empty', 'supermarkets', 'doors', 'close', 'husband', 'samuel', 'played', 'jordi', 'molla', 'switches', 'instant', 'laid', 'back', 'family', 'man', 'wild', 'eyed', 'permanently', 'unshaven', 'nutter', 'injecting', 'julia', 'drug', 'keep', 'sudden', 'cosh', 'molla', 'much', 'respected', 'actor', 'absolutely', 'dreadful', 'comic', 'rather', 'menacing', 'simply', 'cannot', 'pull', 'threatening', 'expression', 'come', 'across', 'barroom', 'slime', 'ball', 'one', 'drink', 'many', 'anything', 'redeem', 'film', 'script', 'clunky', 'plot', 'non', 'existent', 'cast', 'without', 'merit', 'completely', 'without', 'tension', 'full', 'scared', 'moments', 'ausentes', 'exercise', 'make', 'psychological', 'thriller', 'ridiculous', 'overblown', 'one', 'unintentionally', 'hilarious', 'films', 'recent', 'years', 'well', 'worth', 'watch'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these parameters for training our doc2vec model:\n",
    "- dm=0 , distributed bag of words (DBOW) is used.\n",
    "- vector_size=300 , 300 vector dimensional feature vectors.\n",
    "- negative=5 , specifies how many “noise words” should be drawn.\n",
    "- min_count=1, ignores all words with total frequency lower than this.\n",
    "- alpha=0.065 , the initial learning rate.\n",
    "\n",
    "We ill train the model for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2273951.75it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2635242.08it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2175085.31it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2632595.62it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1516017.15it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2779562.35it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2779415.00it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2779415.00it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2383939.98it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1389689.08it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2382233.94it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2779341.33it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1924133.88it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2382233.94it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2001156.52it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2499346.90it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2382342.18it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2779451.84it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2632826.98it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2382585.78it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2379692.94it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2501254.71it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2633091.43it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2501612.75it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2382288.06it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2084644.14it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2174972.52it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2272744.22it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2779488.67it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 2943123.39it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 1667715.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from sklearn import utils\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to get vector from trained Doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(x_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(x_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the data into the logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.89      0.88      0.89      7540\n",
      "    negative       0.88      0.89      0.89      7460\n",
      "\n",
      "    accuracy                           0.89     15000\n",
      "   macro avg       0.89      0.89      0.89     15000\n",
      "weighted avg       0.89      0.89      0.89     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 0.88 which is higher in comparison to Word2vec.\n",
    "    6. BOW with Keras\n",
    "Last considered method is text classification with Keras - a deep learning library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vucht\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 31500 samples, validate on 3500 samples\n",
      "Epoch 1/3\n",
      "31500/31500 [==============================] - 15s 479us/step - loss: 0.3667 - accuracy: 0.8381 - val_loss: 0.3286 - val_accuracy: 0.8611\n",
      "Epoch 2/3\n",
      "31500/31500 [==============================] - 13s 427us/step - loss: 0.2839 - accuracy: 0.8810 - val_loss: 0.3274 - val_accuracy: 0.8614\n",
      "Epoch 3/3\n",
      "31500/31500 [==============================] - 12s 393us/step - loss: 0.2211 - accuracy: 0.9114 - val_loss: 0.3407 - val_accuracy: 0.8597\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "#Seperate dataset into training and testing set\n",
    "train_size = int(len(data) * .7)\n",
    "train_posts = X[:train_size]\n",
    "train_tags = y[:train_size]\n",
    "\n",
    "test_posts = X[train_size:]\n",
    "test_tags = y[train_size:]\n",
    "\n",
    "#Compute the unique words and assign each of those words to indices. We also limit our vocabulary to 1000 of the most popular words.\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "#Create training data that will be fitted in the model.\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "#Encode labels\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "#Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 42us/step\n",
      "Test accuracy: 0.8613333106040955\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III.Conclusion\n",
    "\n",
    "Below is the summary table of model and their classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.8924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2vec and Logistic Regression</th>\n",
       "      <td>0.8854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes Classifier for Multinomial Models</th>\n",
       "      <td>0.8709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW with keras</th>\n",
       "      <td>0.8613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2vec and Logistic Regression</th>\n",
       "      <td>0.8562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Support Vector Machine</th>\n",
       "      <td>0.8504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               accuracy\n",
       "Logistic Regression                              0.8924\n",
       "Doc2vec and Logistic Regression                  0.8854\n",
       "Naive Bayes Classifier for Multinomial Models    0.8709\n",
       "BOW with keras                                   0.8613\n",
       "Word2vec and Logistic Regression                 0.8562\n",
       "Linear Support Vector Machine                    0.8504"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = [\"Naive Bayes Classifier for Multinomial Models\",\"Linear Support Vector Machine\", \"Logistic Regression\",\n",
    "             \"Word2vec and Logistic Regression\", \"Doc2vec and Logistic Regression\", \"BOW with keras\"]\n",
    "acc_list = [0.8709, 0.8504,0.8924, 0.8562, 0.8854, 0.8613]\n",
    "conclusion = pd.DataFrame(acc_list, index = [model_list], columns = [\"accuracy\"]).sort_values(\"accuracy\",ascending=False)\n",
    "conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see Linear Support Vector Machine has the lowest accuracy (~85%) as expected due to its simplicity and Logistic Regression has the highest accuracy (89%). However, it is uncertain to claim which one is the best for text classification. There are different factors that affect the accuracy of each model that have not brought into consideration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
